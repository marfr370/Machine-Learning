#Confusion matrix
k = table(iris$Species, my_data$Species, dnn = c('Actual class', 'Predicted class'))
#Misclassification rate of prediction
n_errors = 1+15+14
error_rate = n_errors/150
#LDA
iris_lda = lda(Species ~ Sepal.Length + Sepal.Width, data = iris)
lda_pred = predict(iris_lda)$class
table(iris$Species, lda_pred, dnn = c('Actual class', 'Predicted class'))
lda_n_errors = 1+15+14
lda_error_rate = lda_n_errors/150
## Task 4 - Generate with Discriminant functions¨
my_new_data = iris
#Sample species
test = sample(unique(iris$Species), 150, replace = TRUE)
#Generate new values
for(i in 1:150) {
if (test[i] == "setosa") {
generate = rmvnorm(1, mean = mu_set, sigma = Pooled_covariance)
my_new_data[i, ]$Sepal.Length <- generate[1,1]
my_new_data[i, ]$Sepal.Width <- generate[1,2]
my_new_data[i, ]$Species <- "setosa"
} else if (test[i] == "versicolor") {
generate1 = rmvnorm(1, mean = mu_ver, sigma = Pooled_covariance)
my_new_data[i, ]$Sepal.Length <- generate1[1,1]
my_new_data[i, ]$Sepal.Width <- generate1[1,2]
my_new_data[i, ]$Species <- "versicolor"
} else if (test[i] == "virginica") {
generate2 = rmvnorm(1, mean = mu_vir, sigma = Pooled_covariance)
my_new_data[i, ]$Sepal.Length <- generate2[1,1]
my_new_data[i, ]$Sepal.Width <- generate2[1,2]
my_new_data[i, ]$Species <- "virginica"
}
}
plot(my_new_data$Sepal.Width, my_new_data$Sepal.Length, pch = c(1,2,3)[my_new_data$Species],
col=c("brown1","dodgerblue1","limegreen")[my_new_data$Species], main = "Generated Plot",
xlab = "Sepal Width", ylab = "Sepal Length", xlim = c(1.8, 5.5), ylim = c(4, 8.5))
legend('topright', legend = c("Setosa", "Versicolor", "Virginica"),
fill = c("brown1","dodgerblue1","limegreen"))
library(nnet)
legend('topright', legend = c("Setosa", "Versicolor", "Virginica"),
fill = c("brown1","dodgerblue1","limegreen"))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
print(iris)
summary(iris)
my_data <- iris
## Task 1 - Scatterplot Sepal
plot(iris$Sepal.Width, iris$Sepal.Length, pch = c(1,2,3)[iris$Species],
col=c("brown1","dodgerblue1","limegreen")[iris$Species], main = "Sepal Scatter",
xlab = "Sepal Width", ylab = "Sepal Length", xlim = c(1.8, 5), ylim = c(4, 8.5))
legend('topright', legend = c("Setosa", "Versicolor", "Virginica"),
fill = c("brown1","dodgerblue1","limegreen"))
## Task 2 - Linear Discriminant Analysis
## Task 2a
#Setosa
x1 <- iris$Sepal.Length[iris$Species == "setosa"]
x2 <- iris$Sepal.Width[iris$Species == "setosa"]
x_setosa = cbind(x1, x2)
mu_x1 = (sum(x1))/50
mu_x2 = (sum(x2))/50
mu_set = rbind(mu_x1, mu_x2)
cov(x_setosa)
setosa_prior = 50/150
#Versicolor
x3 <- iris$Sepal.Length[iris$Species == "versicolor"]
x4 <- iris$Sepal.Width[iris$Species == "versicolor"]
x_versicolor = cbind(x3, x4)
mu_x3 = (sum(x3))/50
mu_x4 = (sum(x4))/50
mu_ver = rbind(mu_x3, mu_x4)
cov(x_versicolor)
versicolor_prior = 50/150
#Virginica
x5 = iris$Sepal.Length[iris$Species == "virginica"]
x6 = iris$Sepal.Width[iris$Species == "virginica"]
x_virginica = cbind(x5, x6)
mu_x5 = (sum(x5))/50
mu_x6 = (sum(x6))/50
mu_vir = rbind(mu_x5, mu_x6)
cov(x_virginica)
virginica_prior = 50/150
## Task 2b
Pooled_covariance = (cov(x_setosa)*50 + cov(x_versicolor)*50 +
cov(x_virginica)*50)/150
## Task 2d
#Setosa
x = cbind(iris$Sepal.Length, iris$Sepal.Width)
Dk_set_x = x %*% solve(Pooled_covariance) %*% mu_set - ((t(mu_set) %*% solve(Pooled_covariance) %*% mu_set) / 2)[1, 1] + log(setosa_prior)
softmax(Dk_set_x)
Dk_ver_x = x %*% solve(Pooled_covariance) %*% mu_ver - ((t(mu_ver) %*% solve(Pooled_covariance) %*% mu_ver) / 2)[1, 1] + log(versicolor_prior)
Dk_vir_x = x %*% solve(Pooled_covariance) %*% mu_vir - ((t(mu_vir) %*% solve(Pooled_covariance) %*% mu_vir) / 2)[1, 1] + log(virginica_prior)
## Task 2e
#Between setosa and versicolor, Dk_set_x = Dk_ver_x
x %*% solve(Pooled_covariance) %*% mu_set - ((t(mu_set) %*% solve(Pooled_covariance) %*% mu_set) / 2)[1, 1] + log(setosa_prior) =
x %*% solve(Pooled_covariance) %*% mu_ver - ((t(mu_ver) %*% solve(Pooled_covariance) %*% mu_ver) / 2)[1, 1] + log(versicolor_prior)
#Between setosa and virginica, Dk_set_x = Dk_vir_x
x %*% solve(Pooled_covariance) %*% mu_set - ((t(mu_set) %*% solve(Pooled_covariance) %*% mu_set) / 2)[1, 1] + log(setosa_prior) =
x %*% solve(Pooled_covariance) %*% mu_vir - ((t(mu_vir) %*% solve(Pooled_covariance) %*% mu_vir) / 2)[1, 1] + log(virginica_prior)
#Between versicolor and virginica, Dk_ver_x = Dk_vir_x
x %*% solve(Pooled_covariance) %*% mu_ver - ((t(mu_ver) %*% solve(Pooled_covariance) %*% mu_ver) / 2)[1, 1] + log(versicolor_prior) =
x %*% solve(Pooled_covariance) %*% mu_vir - ((t(mu_vir) %*% solve(Pooled_covariance) %*% mu_vir) / 2)[1, 1] + log(virginica_prior)
## Task 3 - Prediction with Discriminant function
for(i in 1:150) {
if (Dk_set_x[i, 1] > Dk_ver_x[i, 1] && Dk_set_x[i, 1] > Dk_vir_x[i, 1]) {
my_data[i, ]$Species <- "setosa"
} else if (Dk_ver_x[i, 1] > Dk_set_x[i, 1] && Dk_ver_x[i, 1] > Dk_vir_x[i, 1]) {
my_data[i, ]$Species <- "versicolor"
} else if (Dk_vir_x[i, 1] > Dk_set_x[i, 1] && Dk_vir_x[i, 1] > Dk_ver_x[i, 1]) {
my_data[i, ]$Species <- "virginica"
}
}
plot(my_data$Sepal.Width, my_data$Sepal.Length, pch = c(1,2,3)[my_data$Species],
col=c("brown1","dodgerblue1","limegreen")[my_data$Species], main = "Discriminant Plot",
xlab = "Sepal Width", ylab = "Sepal Length", xlim = c(1.8, 5), ylim = c(4, 8.5))
legend('topright', legend = c("Setosa", "Versicolor", "Virginica"),
fill = c("brown1","dodgerblue1","limegreen"))
#Confusion matrix
k = table(iris$Species, my_data$Species, dnn = c('Actual class', 'Predicted class'))
#Misclassification rate of prediction
n_errors = 1+15+14
error_rate = n_errors/150
#LDA
iris_lda = lda(Species ~ Sepal.Length + Sepal.Width, data = iris)
lda_pred = predict(iris_lda)$class
table(iris$Species, lda_pred, dnn = c('Actual class', 'Predicted class'))
lda_n_errors = 1+15+14
lda_error_rate = lda_n_errors/150
## Task 4 - Generate with Discriminant functions¨
my_new_data = iris
#Sample species
test = sample(unique(iris$Species), 150, replace = TRUE)
#Generate new values
for(i in 1:150) {
if (test[i] == "setosa") {
generate = rmvnorm(1, mean = mu_set, sigma = Pooled_covariance)
my_new_data[i, ]$Sepal.Length <- generate[1,1]
my_new_data[i, ]$Sepal.Width <- generate[1,2]
my_new_data[i, ]$Species <- "setosa"
} else if (test[i] == "versicolor") {
generate1 = rmvnorm(1, mean = mu_ver, sigma = Pooled_covariance)
my_new_data[i, ]$Sepal.Length <- generate1[1,1]
my_new_data[i, ]$Sepal.Width <- generate1[1,2]
my_new_data[i, ]$Species <- "versicolor"
} else if (test[i] == "virginica") {
generate2 = rmvnorm(1, mean = mu_vir, sigma = Pooled_covariance)
my_new_data[i, ]$Sepal.Length <- generate2[1,1]
my_new_data[i, ]$Sepal.Width <- generate2[1,2]
my_new_data[i, ]$Species <- "virginica"
}
}
plot(my_new_data$Sepal.Width, my_new_data$Sepal.Length, pch = c(1,2,3)[my_new_data$Species],
col=c("brown1","dodgerblue1","limegreen")[my_new_data$Species], main = "Generated Plot",
xlab = "Sepal Width", ylab = "Sepal Length", xlim = c(1.8, 5.5), ylim = c(4, 8.5))
legend('topright', legend = c("Setosa", "Versicolor", "Virginica"),
fill = c("brown1","dodgerblue1","limegreen"))
## Task 5 - Logistic regression
iris_multinom = multinom(Species ~ Sepal.Length + Sepal.Width, data = iris)
multinom_pred = predict(iris_multinom, type = "class")
for(i in 1:150) {
my_data[i, ]$Species = multinom_pred[i]
}
plot(my_data$Sepal.Width, my_data$Sepal.Length, pch = c(1,2,3)[my_data$Species],
col=c("brown1","dodgerblue1","limegreen")[my_data$Species], main = "Log Regression Plot",
xlab = "Sepal Width", ylab = "Sepal Length", xlim = c(1.8, 5), ylim = c(4, 8.5))
legend('topright', legend = c("Setosa", "Versicolor", "Virginica"),
fill = c("brown1","dodgerblue1","limegreen"))
table(iris$Species, multinom_pred, dnn = c('Actual class', 'Predicted class'))
multinom_n_errors = 12+13
multinom_error_rate = multinom_n_errors/150
library(boot)
library(ggplot2)
setwd("~/Desktop/TDDE01/tdde01/lab2/ass3")
origin_data = read.csv("communities.csv")
data_without_crimes = origin_data[, 1:100]
n = dim(data_without_crimes)[1]
data_without_crimes= scale(data_without_crimes)
data_without_crimes = as.matrix(data_without_crimes)
library(boot)
library(ggplot2)
setwd("~/Desktop/TDDE01/tdde01/lab2/ass3")
origin_data = read.csv("communities.csv")
data_without_crimes = origin_data[, 1:100]
n = dim(data_without_crimes)[1]
data_without_crimes= scale(data_without_crimes)
data_without_crimes = as.matrix(data_without_crimes)
View(data_without_crimes)
#Calculate covariance matrix
S = 1/n * t(data_without_crimes)%*%data_without_crimes
library(boot)
library(ggplot2)
setwd("~/Desktop/TDDE01/tdde01/lab2/ass3")
origin_data = read.csv("communities.csv")
data_without_crimes = origin_data[, 1:100]
n = dim(data_without_crimes)[1]
data_without_crimes= scale(data_without_crimes)
data_without_crimes = as.matrix(data_without_crimes)
#Calculate covariance matrix
S = 1/n * t(data_without_crimes)%*%data_without_crimes
#calculate eigenvalues from the covariance matrix
eigen_values_vectors = eigen(S, only.values = FALSE)
eigenvalues = eigen_values_vectors$values
# variance covered by principal components as Strings and as numbers
variance = sprintf("%2.3f",eigenvalues/sum(eigenvalues)*100)
variance1 = eigenvalues/sum(eigenvalues)*100
#Calculate how many principal components is needed to cover 95% of variance
var = sum(variance1[1:34])
var_correct = sum(variance1[1:35])
var_2 = sum(variance1[1:2])
var_PC1=sum(variance1[1])
var_PC2=sum(variance1[2])
#plot the variance covered by principal components
#princomp function does the PCA on our data
#The elements of an eigenvector, that is, the values within a particular row of matrix A,
#are the weights aij. These values are called the loadings, and they describe how much
#each variable contributes to a particular principal component.
res=princomp(data_without_crimes)
#plot the variance covered by principal components
#princomp function does the PCA on our data
#The elements of an eigenvector, that is, the values within a particular row of matrix A,
#are the weights aij. These values are called the loadings, and they describe how much
#each variable contributes to a particular principal component.
res=princomp(data_without_crimes)
#pdf('ScreePlot_PCAs.pdf')
screeplot(res)
variance1 = eigenvalues/sum(eigenvalues)*100
variance1
U= res$loadings
U1 = U[,1]
U1_vec = as.vector(U1)
#pdf('Traceplot_PC1.pdf')
plot(U1, main="Traceplot, PC1")
#dev.off()
#Get the 5 varaibles that covers the largest variation in the target variable
tail(sort(abs(U1)),5)
x = data.frame(pc1=res$scores[,1], pc2=res$scores[,2], crimes=origin_data$ViolentCrimesPerPop)
data = data.frame(pc1=res$scores[,1], crimes=origin_data$ViolentCrimesPerPop)
ggplot(x, aes(x=pc1, y=pc2, color=crimes)) + xlab("PC1") + ylab("PC2") +
geom_point() + labs(color="Violent Crimes Per Pop")
polynomial <- lm(crimes ~ poly(pc1, 2), data)  #Doing second degree polynomial regression
plot(data$pc1, data$crimes)   #plotting the data points
mycol <- rgb(0, 120, 185, max = 255, alpha = 30, names = "blue50")
points(x=data$pc1,    #Plotting the fitted line to the data points
y=fitted(polynomial),
pch=16,
col=mycol)
library(boot)
library(ggplot2)
setwd("~/Desktop/TDDE01/tdde01/lab2/ass3")
origin_data = read.csv("communities.csv")
data_without_crimes = origin_data[, 1:100]
n = dim(data_without_crimes)[1]
data_without_crimes= scale(data_without_crimes)
data_without_crimes = as.matrix(data_without_crimes)
#Calculate covariance matrix
S = 1/n * t(data_without_crimes)%*%data_without_crimes
#calculate eigenvalues from the covariance matrix
eigen_values_vectors = eigen(S, only.values = FALSE)
eigenvalues = eigen_values_vectors$values
# variance covered by principal components as Strings and as numbers
variance = sprintf("%2.3f",eigenvalues/sum(eigenvalues)*100)
variance1 = eigenvalues/sum(eigenvalues)*100
#Calculate how many principal components is needed to cover 95% of variance
var = sum(variance1[1:34])
var_correct = sum(variance1[1:35])
var_2 = sum(variance1[1:2])
var_PC1=sum(variance1[1])
var_PC2=sum(variance1[2])
#TASK 2 ----------------------------
#plot the variance covered by principal components
#princomp function does the PCA on our data
#The elements of an eigenvector, that is, the values within a particular row of matrix A,
#are the weights aij. These values are called the loadings, and they describe how much
#each variable contributes to a particular principal component.
res=princomp(data_without_crimes)
#pdf('ScreePlot_PCAs.pdf')
screeplot(res)
#dev.off()
U= res$loadings
U1 = U[,1]
U1_vec = as.vector(U1)
#pdf('Traceplot_PC1.pdf')
plot(U1, main="Traceplot, PC1")
#dev.off()
#Get the 5 varaibles that covers the largest variation in the target variable
tail(sort(abs(U1)),5)
#
x = data.frame(pc1=res$scores[,1], pc2=res$scores[,2], crimes=origin_data$ViolentCrimesPerPop)
data = data.frame(pc1=res$scores[,1], crimes=origin_data$ViolentCrimesPerPop)
pdf('ScorePlot_PC1_PC2.pdf')
ggplot(x, aes(x=pc1, y=pc2, color=crimes)) + xlab("PC1") + ylab("PC2") +
geom_point() + labs(color="Violent Crimes Per Pop")
dev.off()
polynomial <- lm(crimes ~ poly(pc1, 2), data)  #Doing second degree polynomial regression
#Fitting a line to the points
summary(polynomial)
pdf('Scatterplot_nobands.pdf')
plot(data$pc1, data$crimes)   #plotting the data points
mycol <- rgb(0, 120, 185, max = 255, alpha = 30, names = "blue50")
points(x=data$pc1,    #Plotting the fitted line to the data points
y=fitted(polynomial),
pch=16,
col=mycol)
dev.off()
#How random values are to be generated
rng=function(data1, polynomial){
data2=data.frame(Crime=data1$crimes, pc1=data1$pc1)
n=length(data$crimes)
#Generate new Crime level
data2$crimes=rnorm(n=n,predict(polynomial, newdata=data2),sd(polynomial$residuals))
return(data2)
}
f1=function(data2){
result <- lm(crimes~poly(pc1,2), data=data2) #Fit polynomial model
#Predict valies for all Crime values from the original data
newCrime=predict(result, newdata = data)
return(newCrime)
}
res_conf=boot(data, statistic=f1, R=1000, mle=polynomial, ran.gen=rng, sim="parametric")
f2=function(data3){
result <- lm(crimes~poly(pc1,2), data=data3) #fit polynomial model
#predict values for all Area values from the original data
Newcrimes=predict(result,newdata=data)
n=length(data3$crimes)
predictedCrimes=rnorm(n,Newcrimes, sd(polynomial$residuals))
return(predictedCrimes)
}
res_pred=boot(data, statistic=f2, R=10000, mle=polynomial, ran.gen=rng, sim="parametric")
env_conf=envelope(res_conf) #compute confidence bands
env_pred=envelope(res_pred) #Compute prediction bands
#pdf('Scatterplot.pdf')
ggplot(data=data) +
geom_point(mapping = aes(x=pc1, y=crimes), shape=1) +
geom_line(mapping= aes(x=pc1, y=fitted(polynomial), color="red")) +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[2,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[1,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[1,]), color="#52854C") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[2,]), color="#52854C") +
xlab("PC1") +
ylab("crimes")
#dev.off()
S
View(S)
View(S)
?eigen
# variance covered by principal components as Strings and as numbers.
# There are as many Principal components as variables in the original data
# All principal components are perpendicular to each other
variance = sprintf("%2.3f",eigenvalues/sum(eigenvalues)*100)
variance
variance = sprintf("%2.3f",eigenvalues/100)
eigenvalues
# variance covered by principal components as Strings and as numbers.
# There are as many Principal components as variables in the original data
# All principal components are perpendicular to each other
sum(eigenvalues)
eigenvalues
variance1[2]
var_PC1=variance1[1]
var_PC2=variance1[2]
#plot the variance covered by principal components
#princomp function does the PCA on our data
#The elements of an eigenvector, that is, the values within a particular row of matrix A,
#are the weights aij. These values are called the loadings, and they describe how much
#each variable contributes to a particular principal component.
res=princomp(data_without_crimes)
#pdf('ScreePlot_PCAs.pdf')
screeplot(res)
View(res)
# Getting the loadings for PC1
U1 = U[1,]
plot(U1, main="Traceplot, PC1")
View(res)
?screeplot
?princomp
# Getting the loadings for PC1
U1 = U[,1]
U1_vec = as.vector(U1)
plot(U1, main="Traceplot, PC1")
#Get the 5 varaibles that covers the largest variation in the target variable
tail(sort(abs(U1)),5)
?princomp
data = data.frame(pc1=res$scores[,1], crimes=origin_data$ViolentCrimesPerPop)
ggplot(x, aes(x=pc1, y=pc2, color=crimes)) + xlab("PC1") + ylab("PC2") +
geom_point() + labs(color="Violent Crimes Per Pop")
?princomp
res$scores
View(res)
ggplot(x, aes(x=pc1, y=pc2, color=crimes)) + xlab("PC1") + ylab("PC2") +
geom_point() + labs(color="Violent Crimes Per Pop")
plot(data$pc1, data$crimes)   #plotting the data points
ggplot(x, aes(x=pc1, y=pc2, color=crimes)) + xlab("PC1") + ylab("PC2") +
geom_point() + labs(color="Violent Crimes Per Pop")
View(env_conf)
View(data_without_crimes)
View(data)
View(origin_data)
?points
?envelope
library(boot)
library(ggplot2)
setwd("~/Desktop/TDDE01/tdde01/lab2/ass3")
origin_data = read.csv("communities.csv")
#Scaling all the data except for ViolentCrimesPerPop
data_without_crimes = origin_data[, 1:100]
data_without_crimes= scale(data_without_crimes)
data_without_crimes = as.matrix(data_without_crimes)
# Calculate covariance matrix, S is a 100x100 matrix with the covariances
S = 1/n * t(data_without_crimes)%*%data_without_crimes
# Calculate eigenvalues from the covariance matrix
# Eigenvectors of the Covariance matrix are actually the directions of the axes where there is the most variance(most information) and that we call Principal Components.
# Eigenvalues of the Covariance matrix contains the amount of variance
# Eigen() func on covariance matrix with only values=FALSE returns both eigenvectors and eigenvalues. The eigenvalues are sorted in descending order
eigen_values_vectors = eigen(S, only.values = FALSE)
eigenvalues = eigen_values_vectors$values
# variance covered by principal components as Strings and as numbers.
# There are as many Principal components as variables in the original data
# All principal components are perpendicular to each other
# Calculating how much variance in % (therefore multiplying by 100 in denominator) that an eigenvalue covers of the total variation in the data.
variance = sprintf("%2.3f",eigenvalues/sum(eigenvalues)*100)
variance1 = eigenvalues/sum(eigenvalues)*100
#Calculate how many principal components is needed to cover 95% of variance
var = sum(variance1[1:34]) #Dosen't quite reach 95%
var_correct = sum(variance1[1:35]) #Covers more that 95%
var_2 = sum(variance1[1:2]) #How much variance PC1 and PC2 accounts for in the original data
var_PC1=variance1[1]
var_PC2=variance1[2]
#TASK 2 ----------------------------
#plot the variance covered by principal components
#princomp function does the PCA on our data
#Loadings describe how much each variable contributes to a particular principal component.
res=princomp(data_without_crimes)
screeplot(res)
U= res$loadings
# Getting the eigenvector i.e the loadings for PC1. The loadings define the (cosine of angles) i.e. how the vector is positioned in the n-dimensional space
U1 = U[,1]
U1_vec = as.vector(U1)
plot(U1, main="Traceplot, PC1")
#Get the 5 varaibles that covers the largest variation in the target variable by absolute value
tail(sort(abs(U1)),5)
# The ViolentCrimesPerPop is projected onto the 2 dimensional PC1-PC2 plane.
x = data.frame(pc1=res$scores[,1], pc2=res$scores[,2], crimes=origin_data$ViolentCrimesPerPop)
ggplot(x, aes(x=pc1, y=pc2, color=crimes)) + xlab("PC1") + ylab("PC2") +
geom_point() + labs(color="Violent Crimes Per Pop")
polynomial <- lm(crimes ~ poly(pc1, 2), data)  #Doing second degree polynomial regression
#Fitting a line to the points
summary(polynomial)
plot(data$pc1, data$crimes)   #plotting the data points, e.g what value the crime level has for different scores of PC1.
mycol <- rgb(0, 120, 185, max = 255, alpha = 30, names = "blue50")
points(x=data$pc1,    #Plotting the fitted line to the data points
y=fitted(polynomial),
pch=16,
col=mycol)
dev.off()
data = data.frame(pc1=res$scores[,1], crimes=origin_data$ViolentCrimesPerPop)
########################
###   BOOTSTRAP
### resampling a known distribution function, whose parameters are estimated from our sample
########################
#How random values are to be generated
rng=function(data1, polynomial){
data2=data.frame(Crime=data1$crimes, pc1=data1$pc1)
n=length(data$crimes)
data2$crimes=rnorm(n=n,predict(polynomial, newdata=data2),sd(polynomial$residuals)) #Randomizing a new set of crime levels based on our polynomial regression
return(data2)
}
f1=function(data2){
result <- lm(crimes~poly(pc1,2), data=data2) #Fit polynomial model
newCrime=predict(result, newdata = data) #Fitting our new data to a polynomial regression model
return(newCrime)
}
res_conf=boot(data, statistic=f1, R=1000, mle=polynomial, ran.gen=rng, sim="parametric")
f2=function(data3){
result <- lm(crimes~poly(pc1,2), data=data3) #fit polynomial model
Newcrimes=predict(result,newdata=data)
n=length(data3$crimes)
predictedCrimes=rnorm(n,Newcrimes, sd(polynomial$residuals))
return(predictedCrimes)
}
res_pred=boot(data, statistic=f2, R=10000, mle=polynomial, ran.gen=rng, sim="parametric")
env_conf=envelope(res_conf) #compute confidence bands
env_pred=envelope(res_pred) #Compute prediction bands
#pdf('Scatterplot.pdf')
ggplot(data=data) +
geom_point(mapping = aes(x=pc1, y=crimes), shape=1) +
geom_line(mapping= aes(x=pc1, y=fitted(polynomial), color="red")) +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[2,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[1,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[1,]), color="#52854C") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[2,]), color="#52854C") +
xlab("PC1") +
ylab("crimes")
#dev.off()
#pdf('Scatterplot.pdf')
ggplot(data=data) +
geom_point(mapping = aes(x=pc1, y=crimes), shape=1) +
geom_line(mapping= aes(x=pc1, y=fitted(polynomial), color="red")) +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[2,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[1,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[1,]), color="#52854C") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[2,]), color="#52854C") +
xlab("PC1") +
ylab("crimes")
#pdf('Scatterplot.pdf')
ggplot(data=data) +
geom_point(mapping = aes(x=pc1, y=crimes), shape=1) +
geom_line(mapping= aes(x=pc1, y=fitted(polynomial), color="red")) +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[2,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_conf$point[1,]), color="#00AFBB") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[1,]), color="#52854C") +
geom_line(mapping =  aes(x = pc1, y = env_pred$point[2,]), color="#52854C") +
xlab("PC1") +
ylab("crimes")
